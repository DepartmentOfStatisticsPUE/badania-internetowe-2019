---
title: "Web-scraping w R"
output: html_notebook
---


# R 

Najważniejsze pakiety:

+ `rvest`
+ `xml2`
+ `stringr` albo `stringi`

Inne przydatne pakiety:

+ `RSelenium`

Więcej informacji: https://cran.r-project.org/web/views/WebTechnologies.html


```{r}
library(rvest)
library(stringr)

page <- read_html("https://www.otodom.pl/wynajem/mieszkanie/poznan/?search%5Bdist%5D=0&search%5Bsubregion_id%5D=462&search%5Bcity_id%5D=1")

page %>%
  html_nodes("li.offer-item-price") %>%
  html_text() %>%
  str_replace_all("\n|/mc|zł| ","") %>%
  str_replace(",",".") %>%
  as.numeric() -> prices

prices


page %>%
  html_nodes("li.offer-item-area") %>%
  html_text() %>%
  str_replace_all("m²| ","") %>%
  str_replace(",",".") %>%
  as.numeric() -> floor_area

floor_area
```


# Python

+ requests -- wydanie zapytan
+ lxml -- parsowanie htmla

Narzędzia do webscrapping

+ BeautifulSoup 
+ selenium



Wesja w Pythonie (rozwiązanie zaproponowane przez Panią Zuzannę)

```{python, engine.path = "~/anaconda3/bin/python"}
from lxml import html
import requests
page = requests.get('https://www.otodom.pl/wynajem/mieszkanie/poznan/?search%5Bdist%5D=0&search%5Bsubregion_id%5D=462&search%5Bcity_id%5D=1')
tree = html.fromstring(page.content)
#Lista cen
prices = tree.xpath('//li[@class="offer-item-price"]/text()')
#Usunięcie spacji, znaczników nowej linii i niepotrzebnego tekstu
prices = [x.strip().replace(' ', '').replace('zł/mc', '') for x in prices]
#Zamiana na typ integer zamiast tekstowego
prices = [int(x) for x in prices]

#Lista powierzchni
area = tree.xpath('//li[@class="hidden-xs offer-item-area"]/text()')


print('Prices: ', prices)
print('Area: ', area)
```

Kolejna propozycja, tym razem od Pana Bartosza

```{python, engine.path = "~/anaconda3/bin/python"}
import urllib.request
from bs4 import BeautifulSoup
from urllib.request import Request, urlopen

#zmienna web zawierająca adres strony
web = Request('https://www.otodom.pl/wynajem/mieszkanie/poznan/?searc'
              'h%5Bdist%5D=0&search%5Bsubregion_id%5D=462&search%5Bcit'
              'y_id%5D=1', headers={'User-Agent': "Mozilla/5.0"})

#odczytywanie strony
strona = urlopen(web).read()
soup =  BeautifulSoup(strona, 'html.parser')

#szukanie cen
prices = soup.find_all('li', class_='offer-item-price')

######## dodatek od MB
#prices = soup.select('li.offer-item-price') ## alternatywa z selectem i css
prices = [i.text.strip().replace(' ', '').replace('zł/mc', '').replace(',', '.') for i in prices]
######## dodatek od MB

## alternatywne rozwiaznaie

print(prices)
```

# Bash

Required: 

+ html-xml-utils
+ wget

```{bash}
wget -qO- "https://www.otodom.pl/wynajem/mieszkanie/poznan/?search%5Bdist%5D=0&search%5Bsubregion_id%5D=462&search%5Bcity_id%5D=1" | 
  hxnormalize -x | 
  hxselect "li.offer-item-price"
```

